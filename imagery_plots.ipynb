{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21781074-081b-45b8-bbf0-8aad2ab31c1f",
   "metadata": {},
   "source": [
    "# Methods Paper Imagery Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567882e9-11d5-44a1-aeef-799d4ee5e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "os.environ[\"GDAL_DATA\"] = \"/Users/parndt/anaconda3/envs/eeicelakes-env/share/gdal\"\n",
    "os.environ[\"PROJ_LIB\"] = \"/Users/parndt/anaconda3/envs/eeicelakes-env/share/proj\"\n",
    "os.environ[\"PROJ_DATA\"] = \"/Users/parndt/anaconda3/envs/eeicelakes-env/share/proj\"\n",
    "import ee\n",
    "import h5py\n",
    "import math\n",
    "import datetime\n",
    "import requests\n",
    "import traceback\n",
    "import shapely\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "from datetime import datetime \n",
    "import rasterio as rio\n",
    "from rasterio import plot as rioplot\n",
    "from rasterio import warp\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from cmcrameri import cm as cmc\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from lakeanalysis.utils import dictobj, convert_time_to_string, read_melt_lake_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7ccf6e9-c11a-4d69-905b-67dce0cdef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_path_csv = '/Volumes/nox/Philipp/IceLakesRun1/GlacierLakeDetectionICESat2/GLD1_all_lakes.csv'\n",
    "# out_path_csv = '/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/GLD2_lakestats_for-wais_ross-fix_gooddata.csv'\n",
    "# # out_path_csv = '/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/GLD2_all_returned_lakes.csv'\n",
    "# df = pd.read_csv(out_path_csv)\n",
    "# df_lakes = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6be411-fd18-4d75-9df4-82b2c7678ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = cmc.batlow(np.linspace(0,1,10))\n",
    "# print('palette: [', end='')\n",
    "# for i,c in enumerate(cols):\n",
    "#     cl = np.round(c[:3]*255.0).astype(np.uint8)\n",
    "#     print(\"'#{:02x}{:02x}{:02x}'\".format(*cl), end='')\n",
    "#     if i < (len(cols)-1):\n",
    "#         print(', ', end='')\n",
    "# print('],')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd6ed8f-7842-49d2-bb1b-2a13ad8393dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_bands = ['B4', 'B3', 'B2']\n",
    "viz_bands_rename = ['R', 'G', 'B']\n",
    "min_sun_elevation = 20\n",
    "\n",
    "#####################################################################\n",
    "def get_cloudfree_image_collection(area_of_interest, date_time, days_buffer, max_cloud_scene=50, max_cloud_mask=20):\n",
    "    \n",
    "    datetime_requested = datetime.strptime(date_time, '%Y-%m-%dT%H:%M:%SZ')\n",
    "    start_date = (datetime_requested - timedelta(days=days_buffer)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_date = (datetime_requested + timedelta(days=days_buffer)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    # print('Looking for images from %s to %s' % (start_date, end_date), end=' ')\n",
    "    \n",
    "    def get_sentinel2_collection(area_of_interest, start_date, end_date):\n",
    "        sentinel2_collection = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "                                .filterBounds(area_of_interest)\n",
    "                                .filterDate(start_date, end_date)\n",
    "                                .filterMetadata('MEAN_SOLAR_ZENITH_ANGLE', 'less_than', ee.Number(90).subtract(min_sun_elevation)))\n",
    "    \n",
    "        s2cloudless_collection = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "                                  .filterBounds(area_of_interest)\n",
    "                                  .filterDate(start_date, end_date))\n",
    "    \n",
    "        return (ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "            'primary': sentinel2_collection,\n",
    "            'secondary': s2cloudless_collection,\n",
    "            'condition': ee.Filter.equals(**{\n",
    "                'leftField': 'system:index',\n",
    "                'rightField': 'system:index'\n",
    "            })\n",
    "        })))\n",
    "    \n",
    "    def add_cloud_bands_S2(image):\n",
    "        cloud = ee.Image(image.get('s2cloudless')).select('probability').rename('cloudScore')\n",
    "        scene_id = image.get('PRODUCT_ID')\n",
    "        return image.addBands(cloud).set('scene_id', scene_id)\n",
    "    \n",
    "    def mask_S2(img):\n",
    "        mask = img.select('cloudScore').lt(max_cloud_mask)\n",
    "        return img.updateMask(mask)\n",
    "    \n",
    "    def normalize_brightness_S2(image):\n",
    "        return image.addBands(image.select(viz_bands).rename(viz_bands_rename))\n",
    "    \n",
    "    def get_landsat_collection(area_of_interest, start_date, end_date):\n",
    "        L8T1 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA')\n",
    "        L8T2 = ee.ImageCollection('LANDSAT/LC08/C02/T2_TOA')\n",
    "        L9T1 = ee.ImageCollection('LANDSAT/LC09/C02/T1_TOA')\n",
    "        L9T2 = ee.ImageCollection('LANDSAT/LC09/C02/T2_TOA')\n",
    "        return (L8T1.merge(L8T2).merge(L9T2).merge(L9T2)\n",
    "                .filterBounds(area_of_interest)\n",
    "                .filterDate(start_date, end_date)\n",
    "                   .filterMetadata('SUN_ELEVATION', 'greater_than', min_sun_elevation))\n",
    "    \n",
    "    def landsat_cloud_score(image):\n",
    "        cloud = ee.Algorithms.Landsat.simpleCloudScore(image).select('cloud').rename('cloudScore')\n",
    "        scene_id = image.get('LANDSAT_PRODUCT_ID')\n",
    "        return image.addBands(cloud).set('scene_id', scene_id)\n",
    "    \n",
    "    def mask_landsat(img):\n",
    "        mask = img.select('cloudScore').lt(max_cloud_mask)\n",
    "        return img.updateMask(mask)\n",
    "    \n",
    "    def normalize_brightness_LST(image):\n",
    "        return image.addBands(image.select(viz_bands).rename(viz_bands_rename))\n",
    "    \n",
    "    def get_sentinel2_cloud_collection(area_of_interest, start_date, end_date, max_cloud_scene=50, max_cloud_mask=20):\n",
    "        \n",
    "        def set_cloudiness(img, aoi=area_of_interest):\n",
    "            cloudprob = img.select(['cloudScore']).reduceRegion(reducer=ee.Reducer.mean(), \n",
    "                                                                 geometry=aoi, \n",
    "                                                                 bestEffort=True, \n",
    "                                                                 maxPixels=1e6)\n",
    "            return img.set('ground_track_cloud_prob', cloudprob.get('cloudScore'))\n",
    "        \n",
    "        return (get_sentinel2_collection(area_of_interest, start_date, end_date)\n",
    "                         .map(add_cloud_bands_S2)\n",
    "                         .map(set_cloudiness)\n",
    "                         # .filter(ee.Filter.lt('ground_track_cloud_prob', max_cloud_scene))\n",
    "                         .map(mask_S2)\n",
    "                         .map(normalize_brightness_S2)\n",
    "               )\n",
    "    \n",
    "    def get_landsat_cloud_collection(area_of_interest, start_date, end_date, max_cloud_scene=50, max_cloud_mask=20):\n",
    "        \n",
    "        def set_cloudiness(img, aoi=area_of_interest):\n",
    "            cloudprob = img.select(['cloudScore']).reduceRegion(reducer=ee.Reducer.mean(), \n",
    "                                                                 geometry=aoi, \n",
    "                                                                 bestEffort=True, \n",
    "                                                                 maxPixels=1e6)\n",
    "            return img.set('ground_track_cloud_prob', cloudprob.get('cloudScore'))\n",
    "        \n",
    "        return (get_landsat_collection(area_of_interest, start_date, end_date)\n",
    "                         .map(landsat_cloud_score)\n",
    "                         .map(set_cloudiness)\n",
    "                         # .filter(ee.Filter.lt('ground_track_cloud_prob', max_cloud_scene))\n",
    "                         .map(mask_landsat)\n",
    "                         .map(normalize_brightness_LST)\n",
    "               )\n",
    "    \n",
    "    # def clipToROI(img):\n",
    "    #     return img.clip(area_of_interest)\n",
    "\n",
    "    S2_collection = get_sentinel2_cloud_collection(area_of_interest, start_date, end_date, max_cloud_scene, max_cloud_mask)\n",
    "    LST_collection = get_landsat_cloud_collection(area_of_interest, start_date, end_date, max_cloud_scene, max_cloud_mask)\n",
    "\n",
    "    return S2_collection.merge(LST_collection)\n",
    "\n",
    "#####################################################################\n",
    "def download_imagery(fn, lk, gt, imagery_filename, days_buffer=3, max_cloud_scene=50, max_cloud_mask=20, gamma_value=1.8, \n",
    "                     buffer_factor=1.2, crs_out='EPSG:3031', n_imgs_mosaic=7, scale_out=10, mosaic_method='mosaic'):\n",
    "\n",
    "    lake_mean_delta_time = lk.mframe_data.dt.mean()\n",
    "    ATLAS_SDP_epoch_datetime = datetime(2018, 1, 1, tzinfo=timezone.utc) # 2018-01-01:T00.00.00.000000 UTC, from ATL03 data dictionary \n",
    "    ATLAS_SDP_epoch_timestamp = datetime.timestamp(ATLAS_SDP_epoch_datetime)\n",
    "    lake_mean_timestamp = ATLAS_SDP_epoch_timestamp + lake_mean_delta_time\n",
    "    lake_mean_datetime = datetime.fromtimestamp(lake_mean_timestamp, tz=timezone.utc)\n",
    "    time_format_out = '%Y-%m-%dT%H:%M:%SZ'\n",
    "    is2time = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "\n",
    "    # get the bounding box\n",
    "    lon_rng = gt.lon.max() - gt.lon.min()\n",
    "    lat_rng = gt.lat.max() - gt.lat.min()\n",
    "    fac = 0.25\n",
    "    bbox = [gt.lon.min()-fac*lon_rng, gt.lat.min()-fac*lat_rng, gt.lon.max()+fac*lon_rng, gt.lat.max()+fac*lat_rng]\n",
    "    poly = [(bbox[x[0]], bbox[x[1]]) for x in [(0,1), (2,1), (2,3), (0,3), (0,1)]]\n",
    "    roi = ee.Geometry.Polygon(poly)\n",
    "\n",
    "    # get the earth engine collection\n",
    "    collection_size = 0\n",
    "    if days_buffer > 200:\n",
    "        days_buffer = 200\n",
    "    increment_days = days_buffer\n",
    "    while (collection_size<n_imgs_mosaic) & (days_buffer <= 200):\n",
    "\n",
    "        cloudfree_collection = get_cloudfree_image_collection(area_of_interest=roi, \n",
    "                                                    date_time=is2time, \n",
    "                                                    days_buffer=days_buffer, \n",
    "                                                    max_cloud_scene=max_cloud_scene, \n",
    "                                                    max_cloud_mask=max_cloud_mask)\n",
    "\n",
    "        cloudfree_collection = cloudfree_collection.filter(ee.Filter.lt('ground_track_cloud_prob', max_cloud_scene))\n",
    "        collection_size = cloudfree_collection.size().getInfo()\n",
    "        days_buffer += increment_days\n",
    "    \n",
    "    # get the time difference between ICESat-2 and Sentinel-2 and sort by it \n",
    "    # is2time = lk.date_time\n",
    "                         \n",
    "    def set_time_difference(img, is2time=lake_mean_timestamp):\n",
    "        timediff = ee.Date(lake_mean_timestamp*1000).difference(img.get('system:time_start'), 'second').abs()\n",
    "        return img.set('timediff', timediff)\n",
    "    cloudfree_collection = cloudfree_collection.map(set_time_difference).sort('timediff')\n",
    "\n",
    "    # create a region around the ground track over which to download data\n",
    "    lon_center = gt.lon.mean()\n",
    "    lat_center = gt.lat.mean()\n",
    "    gt_length = gt.x10.max() - gt.x10.min()\n",
    "    point_of_interest = ee.Geometry.Point(lon_center, lat_center)\n",
    "    region_of_interest = point_of_interest.buffer(np.nanmax((gt_length*0.5*buffer_factor,500)))\n",
    "\n",
    "    prod_id = 'no imagery'\n",
    "    if collection_size > 0:\n",
    "        \n",
    "        # stretch the color values \n",
    "        def color_stretch(image):\n",
    "            percentiles = image.select(viz_bands_rename).reduceRegion(**{\n",
    "                'reducer': ee.Reducer.percentile(**{'percentiles': [3, 97], 'outputNames': ['lower', 'upper']}),\n",
    "                'geometry': region_of_interest,\n",
    "                'scale': 30,\n",
    "                'maxPixels': 1e9,\n",
    "                'bestEffort': True\n",
    "            })\n",
    "            lower = percentiles.select(['.*_lower']).values().reduce(ee.Reducer.min())\n",
    "            upper = percentiles.select(['.*_upper']).values().reduce(ee.Reducer.max())\n",
    "            return image.select(viz_bands_rename).unitScale(lower, upper).clamp(0,1).resample('bilinear').reproject(**{'crs': crs_out,'scale': scale_out})\n",
    "\n",
    "        # select the first image for info\n",
    "        # info = cloudfree_collection.getInfo()\n",
    "        # for f in info['features']:\n",
    "        #     print(f['properties']['scene_id'])\n",
    "        #     print(f['properties']['timediff'])\n",
    "        selectedImage = cloudfree_collection.first()\n",
    "        \n",
    "        # limit mosaic to first n images after sorting by timediff\n",
    "        to_mosaic = cloudfree_collection.limit(n_imgs_mosaic).map(color_stretch)\n",
    "        \n",
    "        if mosaic_method == 'mean':\n",
    "            rgb = to_mosaic.mean()\n",
    "        elif mosaic_method == 'median':\n",
    "            rgb = to_mosaic.median()\n",
    "        else:\n",
    "            # mosaic() puts last image in collection on top, so sort by timediff in descending order (the False value)\n",
    "            rgb = to_mosaic.sort('timediff', False).mosaic()\n",
    "            \n",
    "        rgb_gamma = rgb.pow(1/gamma_value)\n",
    "        rgb8bit = rgb_gamma.clamp(0,1).multiply(255).uint8()\n",
    "        \n",
    "        # from the selected image get some stats: product id, cloud probability and time difference from icesat-2\n",
    "        prod_id = selectedImage.get('scene_id').getInfo()\n",
    "        cld_prb = selectedImage.get('ground_track_cloud_prob').getInfo()\n",
    "        s2_timestamp = selectedImage.get('system:time_start').getInfo()\n",
    "        s2datetime = datetime.fromtimestamp(s2_timestamp/1000, tz=timezone.utc)\n",
    "        s2datestr = datetime.strftime(s2datetime, 'time_format_out')\n",
    "        is2datetime = lake_mean_datetime\n",
    "        timediff = s2datetime - is2datetime\n",
    "        timediff_str = '%s' % (timediff)\n",
    "        \n",
    "        # get the download URL and download the selected image\n",
    "        success = False\n",
    "        tries = 0\n",
    "        while (success == False) & (tries <= 10):\n",
    "            try:\n",
    "                downloadURL = rgb8bit.getDownloadUrl({'name': 'mySatelliteImage',\n",
    "                                                          'crs': crs_out,\n",
    "                                                          'scale': scale_out,\n",
    "                                                          'region': region_of_interest,\n",
    "                                                          'filePerBand': False,\n",
    "                                                          'format': 'GEO_TIFF'})\n",
    "        \n",
    "                response = requests.get(downloadURL)\n",
    "                with open(imagery_filename, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "        \n",
    "                # print('--> Downloaded the 8-bit RGB image as %s.' % imagery_filename)\n",
    "                success = True\n",
    "                tries += 1\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                scale *= 2\n",
    "                # print('-> download unsuccessful, increasing scale to %.1f...' % scale)\n",
    "                success = False\n",
    "                tries += 1\n",
    "\n",
    "    return prod_id, timediff_str\n",
    "            \n",
    "#####################################################################\n",
    "def plot_imagery(fn, days_buffer=5, max_cloud_scene=50, max_cloud_mask=20, xlm=[None, None], ylm=[None, None], gamma_value=1.8, imagery_filename=None,\n",
    "                 re_download=True, ax=None, buffer_factor=1.5, crs_out='EPSG:3031', n_imgs_mosaic=7, scale_out=10, mosaic_method='mosaic'):\n",
    "                     \n",
    "    lk = dictobj(read_melt_lake_h5(fn))\n",
    "    time_format_out = '%Y-%m-%dT%H:%M:%SZ'\n",
    "    lake_mean_delta_time = lk.mframe_data.dt.mean()\n",
    "    ATLAS_SDP_epoch_datetime = datetime(2018, 1, 1, tzinfo=timezone.utc) # 2018-01-01:T00.00.00.000000 UTC, from ATL03 data dictionary \n",
    "    ATLAS_SDP_epoch_timestamp = datetime.timestamp(ATLAS_SDP_epoch_datetime)\n",
    "    lake_mean_timestamp = ATLAS_SDP_epoch_timestamp + lake_mean_delta_time\n",
    "    lake_mean_datetime = datetime.fromtimestamp(lake_mean_timestamp, tz=timezone.utc)\n",
    "    lake_mean_time_string = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "    lk.date_time = lake_mean_time_string\n",
    "                     \n",
    "    df = lk.photon_data.copy()\n",
    "    if not xlm[0]:\n",
    "        xlm[0] = df.xatc.min()\n",
    "    if not xlm[1]:\n",
    "        xlm[1] = df.xatc.max()\n",
    "    if not ylm[0]:\n",
    "        ylm[0] = lk.surface_elevation-2*lk.max_depth\n",
    "    if not ylm[1]:\n",
    "        ylm[1] = lk.surface_elevation+lk.max_depth\n",
    "    if not imagery_filename:\n",
    "        imagery_filename = 'imagery' + fn[fn.rfind('/'):].replace('.h5','.tif')\n",
    "    \n",
    "    \n",
    "    df = df[(df.xatc >= xlm[0]) & (df.xatc <= xlm[1]) & (df.h >= ylm[0]) & (df.h <= ylm[1])].reset_index(drop=True).copy()\n",
    "    x_off = np.min(df.xatc)\n",
    "    df.xatc -= x_off\n",
    "    \n",
    "    dfd = lk.depth_data.copy()\n",
    "    dfd.xatc -= x_off\n",
    "\n",
    "    # get the ground track\n",
    "    df['x10'] = np.round(df.xatc, -1)\n",
    "    gt = df.groupby(by='x10')[['lat', 'lon']].median().reset_index()\n",
    "    lon_center = gt.lon.mean()\n",
    "    lat_center = gt.lat.mean()\n",
    "                     \n",
    "    try:\n",
    "        prod_id = 'no imagery'\n",
    "        if ((not os.path.isfile(imagery_filename)) or re_download) and ('modis' not in imagery_filename):\n",
    "            prod_id, dt_str = download_imagery(fn=fn, lk=lk, gt=gt, imagery_filename=imagery_filename, days_buffer=days_buffer, \n",
    "                             max_cloud_scene=max_cloud_scene, max_cloud_mask=max_cloud_mask, gamma_value=gamma_value, \n",
    "                             buffer_factor=buffer_factor, crs_out=crs_out, n_imgs_mosaic=n_imgs_mosaic, scale_out=scale_out,\n",
    "                             mosaic_method=mosaic_method)\n",
    "        \n",
    "        try:\n",
    "            myImage = rio.open(imagery_filename)\n",
    "            \n",
    "            # make the figure\n",
    "            if not ax:\n",
    "                fig, ax = plt.subplots(figsize=[6,6])\n",
    "            \n",
    "            rioplot.show(myImage, ax=ax)\n",
    "            ax.axis('off')\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "    \n",
    "        try:\n",
    "            dt_str = dt_str.split('.')[0]\n",
    "            if dt_str[0] != '-':\n",
    "                dt_str = '+' + dt_str\n",
    "            text = 'imagery time difference: %s\\n%s' % (dt_str, prod_id)\n",
    "            ax.text(0.01, 0.01, text, fontsize=6, ha='left', va='bottom', transform=ax.transAxes,\n",
    "               bbox=dict(facecolor='white', alpha=0.7, boxstyle='round,pad=0.1,rounding_size=0.3', lw=0), zorder=3000)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "    \n",
    "        try:\n",
    "            ximg, yimg = warp.transform(src_crs='epsg:4326', dst_crs=myImage.crs, xs=np.array(gt.lon), ys=np.array(gt.lat))\n",
    "            if 'modis' in imagery_filename:\n",
    "                xrng = ximg[-1] - ximg[0]\n",
    "                yrng = yimg[-1] - yimg[0]\n",
    "                fac = 30\n",
    "                # print('using saved modis image')\n",
    "                ax.plot([ximg[-1]+fac*xrng,ximg[0]-fac*xrng], [yimg[-1]+fac*yrng, yimg[0]-fac*yrng], 'k:', lw=1)\n",
    "                ax.annotate('', xy=(ximg[-1]+fac*xrng, yimg[-1]+fac*yrng), xytext=(ximg[0]-fac*xrng, yimg[0]-fac*yrng),\n",
    "                                 arrowprops=dict(width=0, lw=0, headwidth=5, headlength=5, color='k'),zorder=1000)\n",
    "                # ax.plot(ximg, yimg, 'r-', lw=1, zorder=5000)\n",
    "            else:\n",
    "                # print('plotting ground track')\n",
    "                ax.annotate('', xy=(ximg[-1], yimg[-1]), xytext=(ximg[0], yimg[0]),\n",
    "                                 arrowprops=dict(width=0.7, headwidth=5, headlength=5, color='k'),zorder=1000)\n",
    "                try:\n",
    "                    isdepth = dfd.depth>0\n",
    "                    bed = dfd.h_fit_bed\n",
    "                    bed[~isdepth] = np.nan\n",
    "                    bed[(dfd.depth>2) & (dfd.conf < 0.3)] = np.nan\n",
    "                    surf = np.ones_like(dfd.xatc) * lk.surface_elevation\n",
    "                    surf[~isdepth] = np.nan\n",
    "                    xatc_surf = np.array(dfd.xatc)[~np.isnan(surf)]\n",
    "                    lon_bed = np.array(dfd.lon)\n",
    "                    lat_bed = np.array(dfd.lat)\n",
    "                    lon_bed[(np.isnan(surf)) & (np.isnan(bed))] = np.nan\n",
    "                    lat_bed[(np.isnan(surf)) & (np.isnan(bed))] = np.nan\n",
    "                    xb, yb = warp.transform(src_crs='epsg:4326', dst_crs=myImage.crs, xs=lon_bed, ys=lat_bed)\n",
    "                    ax.plot(xb, yb, 'r-', lw=1, zorder=5000)\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            \n",
    "        if not ax:\n",
    "            fig.tight_layout(pad=0)\n",
    "    \n",
    "        return myImage, lon_center, lat_center\n",
    "    except: \n",
    "        return None, lon_center, lat_center\n",
    "        traceback.print_exc()\n",
    "\n",
    "                     \n",
    "#####################################################################\n",
    "def plotIS2(fn, ax=None, xlm=[None, None], ylm=[None,None], cmap=cmc.lapaz_r, name='ICESat-2 data'):\n",
    "    lk = dictobj(read_melt_lake_h5(fn))\n",
    "    time_format_out = '%Y-%m-%dT%H:%M:%SZ'\n",
    "    lake_mean_delta_time = lk.mframe_data.dt.mean()\n",
    "    ATLAS_SDP_epoch_datetime = datetime(2018, 1, 1, tzinfo=timezone.utc) # 2018-01-01:T00.00.00.000000 UTC, from ATL03 data dictionary \n",
    "    ATLAS_SDP_epoch_timestamp = datetime.timestamp(ATLAS_SDP_epoch_datetime)\n",
    "    lake_mean_timestamp = ATLAS_SDP_epoch_timestamp + lake_mean_delta_time\n",
    "    lake_mean_datetime = datetime.fromtimestamp(lake_mean_timestamp, tz=timezone.utc)\n",
    "    lake_mean_time_string = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "    lk.date_time = lake_mean_time_string\n",
    "    df = lk.photon_data.copy()\n",
    "    dfd = lk.depth_data.copy()\n",
    "\n",
    "    try:\n",
    "        isdepth = dfd.depth>0\n",
    "        bed = dfd.h_fit_bed\n",
    "        bed[~isdepth] = np.nan\n",
    "        bed[(dfd.depth>2) & (dfd.conf < 0.3)] = np.nan\n",
    "        surf = np.ones_like(dfd.xatc) * lk.surface_elevation\n",
    "        surf[~isdepth] = np.nan\n",
    "        surf_only = surf[~np.isnan(surf)]\n",
    "        bed_only = bed[(~np.isnan(surf)) & (~np.isnan(bed))]\n",
    "        xatc_surf = np.array(dfd.xatc)[~np.isnan(surf)]\n",
    "        xatc_bed = np.array(dfd.xatc)[(~np.isnan(surf)) & (~np.isnan(bed))]\n",
    "        \n",
    "        # make the figure\n",
    "        if not ax:\n",
    "            fig, ax = plt.subplots(figsize=[8,5])\n",
    "    \n",
    "        df['is_afterpulse']= df.prob_afterpulse > np.random.uniform(0,1,len(df))\n",
    "        if not cmap:\n",
    "            # ax.scatter(df.xatc, df.h, s=1, c='k')\n",
    "            ax.scatter(df.xatc[~df.is_afterpulse], df.h[~df.is_afterpulse], s=1, c='k')\n",
    "        else:\n",
    "            ax.scatter(df.xatc[~df.is_afterpulse], df.h[~df.is_afterpulse], s=1, c=df.snr, cmap=cmap)\n",
    "        \n",
    "        ax.scatter(dfd.xatc[isdepth], dfd.h_fit_bed[isdepth], s=4, color='r', alpha=dfd.conf[isdepth])\n",
    "        ax.plot(dfd.xatc, dfd.h_fit_bed, color='gray', lw=0.5)\n",
    "        \n",
    "        ax.plot(dfd.xatc, bed, color='r', lw=1)\n",
    "        ax.plot(dfd.xatc, surf, color='C0', lw=1)\n",
    "    except:\n",
    "        ax.scatter(df.xatc, df.h, s=1, c='k')\n",
    "        ax.plot(dfd.xatc, dfd.h_fit_bed, 'r-')\n",
    "        ax.plot(dfd.xatc, np.ones_like(dfd.xatc) * lk.surface_elevation, 'b-')\n",
    "\n",
    "    # add the length of surface\n",
    "    try:\n",
    "        arr_y = lk.surface_elevation+lk.max_depth*0.25\n",
    "        x_start = np.min(xatc_surf)\n",
    "        x_end = np.max(xatc_surf)\n",
    "        x_mid = (x_end + x_start) / 2\n",
    "        len_surf_m = np.floor((x_end-x_start)/100)*100\n",
    "        len_surf_km = len_surf_m/1000\n",
    "        arr_x1 = x_mid - len_surf_m / 2\n",
    "        arr_x2 = x_mid + len_surf_m / 2\n",
    "        ax.annotate('', xy=(arr_x1, arr_y), xytext=(arr_x2, arr_y),\n",
    "                             arrowprops=dict(width=0.7, headwidth=5, headlength=5, color='C0'),zorder=1000)\n",
    "        ax.annotate('', xy=(arr_x2, arr_y), xytext=(arr_x1, arr_y),\n",
    "                             arrowprops=dict(width=0.7, headwidth=5, headlength=5, color='C0'),zorder=1000)\n",
    "        ax.text(x_mid, arr_y, '%.1f km' % len_surf_km, fontsize=12, ha='center', va='bottom', color='C0', fontweight='bold',\n",
    "                bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.2,rounding_size=0.5', lw=0))\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # add the max depth\n",
    "    try:\n",
    "        if np.sum(np.isnan(bed)) < len(bed):\n",
    "            y_low = np.nanmin(bed)\n",
    "            if y_low < (lk.surface_elevation - 2 * lk.max_depth):\n",
    "                bed[bed < lk.surface_elevation - 2 * lk.max_depth] = np.nan\n",
    "                if np.sum(np.isnan(bed)) < len(bed):\n",
    "                    y_low = np.nanmin(bed)\n",
    "            if np.sum(np.isnan(bed)) < len(bed):\n",
    "                y_up = lk.surface_elevation\n",
    "                arr_x = xatc_bed[np.argmin(bed_only)]\n",
    "                xlm = (df.xatc.min(), df.xatc.max())\n",
    "                arr_x = xlm[0] - 0.0* (xlm[1] - xlm[0])\n",
    "                y_len = y_up - y_low\n",
    "                y_mid = (y_up + y_low) / 2\n",
    "                arr_len = y_len\n",
    "                arr_y1 = y_mid + arr_len / 2\n",
    "                arr_y2 = y_mid - arr_len / 2\n",
    "                ref_index = 1.33\n",
    "                dep_round = np.round(y_len / ref_index, 1)\n",
    "                ax.annotate('', xy=(arr_x, arr_y2), xytext=(arr_x, arr_y1),\n",
    "                                     arrowprops=dict(width=0.7, headwidth=5, headlength=5, color='r'),zorder=1000)\n",
    "                ax.annotate('', xy=(arr_x, arr_y1), xytext=(arr_x, arr_y2),\n",
    "                                     arrowprops=dict(width=0.7, headwidth=5, headlength=5, color='r'),zorder=1000)\n",
    "                ax.text(arr_x, y_mid, '%.1f m' % dep_round, fontsize=12, ha='right', va='center', color='r', fontweight='bold',\n",
    "                        bbox=dict(facecolor='white', alpha=0.8, lw=0, boxstyle='round,pad=0.2,rounding_size=0.5'), rotation=90)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # add the title\n",
    "    try:\n",
    "        datestr = datetime.strftime(datetime.strptime(lk.date_time,'%Y-%m-%dT%H:%M:%SZ'), '%d %B %Y %H:%M:%S UTC')\n",
    "        sheet = lk.ice_sheet\n",
    "        region = lk.polygon_filename.split('_')[-1].replace('.geojson', '')\n",
    "        if sheet == 'AIS':\n",
    "            region = region + ' (%s)' % lk.polygon_filename.split('_')[-2]\n",
    "        latstr = lk.lat_str[:-1] + '°' + lk.lat_str[-1]\n",
    "        lonstr = lk.lon_str[:-1] + '°' + lk.lon_str[-1]\n",
    "        description = '%s, %s - %s (%s, %s, %.1fm)\\n%s %s (%s)' % (datestr, sheet, region, latstr, lonstr, lk.surface_elevation, lk.granule_id, lk.gtx, lk.beam_strength)\n",
    "        \n",
    "        ax.text(0.5, 1.0, description, fontsize=8, ha='center', va='top', transform=ax.transAxes,\n",
    "               bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.2,rounding_size=0.5', lw=0), zorder=3000)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "    try:\n",
    "        xlm = (df.xatc.min(), df.xatc.max())\n",
    "        dp = lk.max_depth\n",
    "        if dp < 2.0:\n",
    "            dp = 2.0\n",
    "        ylm = (lk.surface_elevation-dp*2, lk.surface_elevation+dp)\n",
    "        ax.set_xlim(xlm)\n",
    "        ax.set_ylim(ylm)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    ax.axis('off')\n",
    "\n",
    "    \n",
    "#####################################################################\n",
    "def plot_IS2_imagery(fn, axes=None, xlm=[None,None], ylm=[None,None], cmap=None, days_buffer=5, max_cloud_scene=50, max_cloud_mask=50,\n",
    "                     gamma_value=1.8, imagery_filename=None, re_download=True, img_aspect=3/2, name='ICESat-2 data',\n",
    "                     return_fig=False, n_imgs_mosaic=7, scale_out=10, mosaic_method='mosaic'):\n",
    "\n",
    "    if not axes:\n",
    "        fig = plt.figure(figsize=[12,6], dpi=80)\n",
    "        gs = fig.add_gridspec(1,3)\n",
    "        axp = [fig.add_subplot(gs[0, 0]), fig.add_subplot(gs[0, 1:])]\n",
    "    else:\n",
    "        axp = axes\n",
    "        \n",
    "    ax = axp[1]\n",
    "    try:\n",
    "        plotIS2(fn=fn, ax=ax, xlm=xlm, ylm=ylm, cmap=cmap, name=name)\n",
    "    except:\n",
    "        ax.text(0.5, 0.5, 'plotting error', fontsize=12, ha='center', va='center', transform=ax.transAxes)\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    ax = axp[0]\n",
    "    try:\n",
    "        crs_out = 'EPSG:3413' if '_GrIS_' in fn else 'EPSG:3031'\n",
    "        center_lon, center_lat = 0, 0\n",
    "        img, center_lon, center_lat = plot_imagery(fn=fn, days_buffer=days_buffer, max_cloud_scene=max_cloud_scene, \n",
    "            max_cloud_mask=max_cloud_mask, xlm=xlm, ylm=ylm, gamma_value=gamma_value, imagery_filename=imagery_filename, \n",
    "            re_download=re_download, ax=ax, crs_out=crs_out, n_imgs_mosaic=n_imgs_mosaic, scale_out=scale_out,\n",
    "            mosaic_method=mosaic_method)\n",
    "        \n",
    "        if img:        \n",
    "            if imagery_filename:\n",
    "                if 'modis' in imagery_filename:\n",
    "                    center_x, center_y = warp.transform(src_crs='epsg:4326', dst_crs=img.crs, xs=[center_lon], ys=[center_lat])\n",
    "                    center_x = center_x[0]\n",
    "                    center_y = center_y[0]\n",
    "                    rng = 220000\n",
    "                    if img_aspect > 1:\n",
    "                        ax.set_xlim(center_x - 0.5*rng/img_aspect, center_x + 0.5*rng/img_aspect)\n",
    "                        ax.set_ylim(center_y - 0.5*rng, center_y + 0.5*rng)\n",
    "                    if img_aspect < 1:\n",
    "                        ax.set_xlim(center_x - 0.5*rng, center_x + 0.5*rng)\n",
    "                        ax.set_ylim(center_y - 0.5*rng*img_aspect, center_y + 0.5*rng*img_aspect)\n",
    "                    \n",
    "            elif (img_aspect > 1): \n",
    "                h_rng = img.bounds.top - img.bounds.bottom\n",
    "                cntr = (img.bounds.right + img.bounds.left) / 2\n",
    "                ax.set_xlim(cntr-0.5*h_rng/img_aspect, cntr+0.5*h_rng/img_aspect)\n",
    "            elif img_aspect < 1: \n",
    "                w_rng = img.bounds.right - img.bounds.left\n",
    "                cntr = (img.bounds.top + img.bounds.bottom) / 2\n",
    "                ax.set_ylim(cntr-0.5*w_rng*img_aspect, cntr+0.5*w_rng/img_aspect)\n",
    "    except:\n",
    "        ax.text(0.5, 0.5, 'plotting error', fontsize=12, ha='center', va='center', transform=ax.transAxes)\n",
    "        traceback.print_exc()\n",
    "            \n",
    "    \n",
    "    if not axes:\n",
    "        fig.tight_layout(pad=1, h_pad=0, w_pad=0)\n",
    "        if not name:\n",
    "            name = 'zzz' + lk.polygon_filename.split('_')[-1].replace('.geojson', '')\n",
    "        outname = 'figplots/' + name.replace(' ', '') + fn[fn.rfind('/')+1:].replace('.h5','.jpg')\n",
    "        fig.savefig(outname, dpi=300)\n",
    "\n",
    "    if return_fig:\n",
    "        plt.close(fig)\n",
    "        return center_lon, center_lat, fig\n",
    "    else:\n",
    "        return center_lon, center_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ee862d-d634-4eaf-a26a-e88b76c3e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = '/Users/parndt/jupyterprojects/IceLakesRun2/methods_data/'\n",
    "# searchfor = '.h5'\n",
    "# filelist = [base+f for f in os.listdir(base) \\\n",
    "#             if os.path.isfile(os.path.join(base, f)) & (searchfor in f)]\n",
    "# filelist.sort()\n",
    "# listlength = len(filelist)\n",
    "# print(listlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7c503a-bddb-49df-bfa5-142ec0c72584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25094\n"
     ]
    }
   ],
   "source": [
    "base = '/Users/parndt/jupyterprojects/IceLakesRun2'\n",
    "oldfolder = '/upto21jun2023_data/'\n",
    "searchdir = base + oldfolder\n",
    "searchfor = '.h5'\n",
    "filelist = [searchdir+f for f in os.listdir(searchdir) \\\n",
    "            if os.path.isfile(os.path.join(searchdir, f)) & (searchfor in f)]\n",
    "filelist.sort()\n",
    "listlength = len(filelist)\n",
    "print(listlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83274120-4198-4d21-968b-538d8b3aa917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# filelist = [\n",
    "#     base + 'lake_10000000_AIS_2018-19_simplified_ANT_1000_East_B-C_ATL03_20190128061524_04700212_006_02_gt1r_0006.h5',\n",
    "#            ]\n",
    "\n",
    "# for i, fn in enumerate(filelist):\n",
    "#     display(Image(fn.replace('/methods_data/', '/methods_plots/').replace('.h5', '_imagery.jpg')))\n",
    "\n",
    "filelist = filelist[:10]\n",
    "listlength = len(filelist)\n",
    "print(listlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a71938c-8d83-4846-bda7-94e2aec50c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[####################################################################################################]\n",
      "\n",
      "25094 / 25094 lakes processed (1877 this run)\n",
      "0 days, 4 hrs, 16 mins, 42 secs elapsed\n",
      "0 days, 0 hrs, 0 mins, 8 secs remaining\n",
      "current file: lake_10000000_GrIS_2023_simplified_GRE_2000_SW_ATL03_20230618212225_13671905_006_01_gt3r_0002_imagery.jpg\n",
      "\n",
      "\n",
      "scp -i ~/.ssh/lumosKey parndt@132.239.169.168:/Users/parndt/jupyterprojects/IceLakesRun2/upto21jun2023_plots/lake_10000000_GrIS_2023_simplified_GRE_2000_SW_ATL03_20230618212225_13671905_006_01_gt3r_0002_imagery.jpg /mnt/c/Users/phili/Documents/IceLakesMethods/gooddata/\n"
     ]
    }
   ],
   "source": [
    "##### FOR EVERYTHING UP TO JUN 21, 2023\n",
    "\n",
    "base = '/Users/parndt/jupyterprojects/IceLakesRun2'\n",
    "oldfolder = '/upto21jun2023_data/'\n",
    "searchdir = base + oldfolder\n",
    "searchfor = '.h5'\n",
    "filelist = [searchdir+f for f in os.listdir(searchdir) \\\n",
    "            if os.path.isfile(os.path.join(searchdir, f)) & (searchfor in f)]\n",
    "filelist.sort()\n",
    "listlength = len(filelist)\n",
    "print('\\nThere are %d lake files to process...' % listlength)\n",
    "\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "def time_string(secs):\n",
    "    m, s = divmod(secs, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    d, h = divmod(h, 24)\n",
    "    return '%d days, %d hrs, %d mins, %d secs' % (d, h, m, s)\n",
    "plt.close('all')\n",
    "\n",
    "# startfile = 0\n",
    "# nfiles = 5\n",
    "# for i, fn in enumerate(filelist[startfile:startfile+nfiles]):\n",
    "\n",
    "tstart = time.time()\n",
    "idone = 0\n",
    "for i, fn in enumerate(filelist):\n",
    "\n",
    "    fn_plot = fn.replace(oldfolder, oldfolder.replace('_data/', '_plots/')).replace('.h5', '_imagery.jpg')\n",
    "    fn_imagery = fn.replace(oldfolder, oldfolder.replace('_data/', '_imagery/')).replace('.h5', '_imagery.tif')\n",
    "\n",
    "    if not os.path.isfile(fn_plot):\n",
    "        \n",
    "        tnow = time.time()\n",
    "        selapsed = tnow - tstart\n",
    "        elapsed = time_string(selapsed)\n",
    "        if idone > 0:\n",
    "            sremaining = (listlength-i) / idone * selapsed\n",
    "            remaining = time_string(sremaining)\n",
    "        else:\n",
    "            remaining = 'undefined'\n",
    "        ns = int(np.round((i+1)/listlength*100))\n",
    "        print('\\n[' + '#'*ns + '.'*(100-ns) + ']\\n')\n",
    "        print('%i / %i lakes processed (%i this run)' % (i+1, listlength, idone))\n",
    "        print('%s elapsed' % elapsed)\n",
    "        print('%s remaining' % remaining)\n",
    "        print('current file: %s' % fn_plot.split('/')[-1])\n",
    "        if i < (listlength-1):\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        idone += 1\n",
    "\n",
    "        settings = {\n",
    "            're_download': False,     # True\n",
    "            'img_aspect': 1.0,        # 1.0\n",
    "            'days_buffer': 5,         # 5\n",
    "            'max_cloud_scene': 20,    # 20               (make this smaller, more like 30?)\n",
    "            'max_cloud_mask': 40,     # 50               (make this smaller, more like 30?)\n",
    "            'n_imgs_mosaic': 7,       # 7                (put to one for checking code)\n",
    "            'mosaic_method': 'mean',  # mean             (alternatively \"median\" or \"mosaic\")\n",
    "            'scale_out': 10,          # 10\n",
    "            'gamma_value': 1.0,       # 1.0\n",
    "            'xlm': [None, None],      # [None, None]     (keep at None unless adjusting for a particular plot)\n",
    "            'ylm': [None, None],      # [None, None]     (keep at None unless adjusting for a particular plot)\n",
    "            'return_fig': False       # False\n",
    "        }\n",
    "    \n",
    "        fig = plt.figure(figsize=[10,4.35])\n",
    "        gs = fig.add_gridspec(ncols=9, nrows=1)\n",
    "        \n",
    "        axs = []\n",
    "        axs.append(fig.add_subplot(gs[0, :4])) \n",
    "        axs.append(fig.add_subplot(gs[0, 4:]))\n",
    "\n",
    "        try:\n",
    "            lk = dictobj(read_melt_lake_h5(fn))\n",
    "            \n",
    "            plot_IS2_imagery(fn=fn, imagery_filename=fn_imagery, **settings, axes=axs)\n",
    "            fig.tight_layout(pad=0.3, h_pad=0.3, w_pad=0.4)\n",
    "        except:\n",
    "            axs[0].text(0.5, 0.5, 'plotting error', fontsize=12, ha='center', va='center', transform=axs[0].transAxes)\n",
    "            traceback.print_exc()\n",
    "    \n",
    "        plt.close(fig)\n",
    "        fig.savefig(fn_plot, dpi=600)\n",
    "\n",
    "    # display(Image(fn_plot))\n",
    "\n",
    "print('\\n\\nscp -i ~/.ssh/lumosKey parndt@132.239.169.168:%s /mnt/c/Users/phili/Documents/IceLakesMethods/gooddata/' % fn_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ae88b11-53a0-425e-8814-e83a7646425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50188\n"
     ]
    }
   ],
   "source": [
    "! ls /Users/parndt/jupyterprojects/IceLakesRun2/upto21jun2023_data | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a11667f-0250-4bcf-9bc7-4d16f9605905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25094\n"
     ]
    }
   ],
   "source": [
    "! ls /Users/parndt/jupyterprojects/IceLakesRun2/upto21jun2023_plots | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15aafec-6ac9-47ab-beeb-2700c061979c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd043f54-bd2a-4b40-84d3-6eb3ea661b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d57f0-3b11-43b1-809b-d26b3d93e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FOR METHODS PAPER\n",
    "\n",
    "base = '/Users/parndt/jupyterprojects/IceLakesRun2/methods_data/'\n",
    "searchfor = '.h5'\n",
    "filelist = [base+f for f in os.listdir(base) \\\n",
    "            if os.path.isfile(os.path.join(base, f)) & (searchfor in f)]\n",
    "filelist.sort()\n",
    "listlength = len(filelist)\n",
    "print(listlength)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "# startfile = 0\n",
    "# nfiles = 5\n",
    "# for i, fn in enumerate(filelist[startfile:startfile+nfiles]):\n",
    "\n",
    "for i, fn in enumerate(filelist):\n",
    "\n",
    "    fn_plot = fn.replace('/methods_data/', '/methods_plots/').replace('.h5', '_imagery.jpg')\n",
    "    fn_imagery = fn.replace('/methods_data/', '/methods_imagery/').replace('.h5', '_imagery.tif')\n",
    "\n",
    "    print('%5i / %5i : %s                      ' % (i+1, listlength, fn_plot.split('/')[-1]), end='\\r')\n",
    "\n",
    "    settings = {\n",
    "        're_download': True,      # True\n",
    "        'img_aspect': 1.0,        # 1.0\n",
    "        'days_buffer': 5,         # 5\n",
    "        'max_cloud_scene': 20,    # 20               (make this smaller, more like 30?)\n",
    "        'max_cloud_mask': 40,     # 50               (make this smaller, more like 30?)\n",
    "        'n_imgs_mosaic': 7,       # 7                (put to one for checking code)\n",
    "        'mosaic_method': 'mean',  # mean             (alternatively \"median\" or \"mosaic\")\n",
    "        'scale_out': 10,          # 10\n",
    "        'gamma_value': 1.0,       # 1.0\n",
    "        'xlm': [None, None],      # [None, None]     (keep at None unless adjusting for a particular plot)\n",
    "        'ylm': [None, None],      # [None, None]     (keep at None unless adjusting for a particular plot)\n",
    "        'return_fig': False       # False\n",
    "    }\n",
    "\n",
    "    fig = plt.figure(figsize=[10,4.35])\n",
    "    gs = fig.add_gridspec(ncols=9, nrows=1)\n",
    "    \n",
    "    axs = []\n",
    "    axs.append(fig.add_subplot(gs[0, :4])) \n",
    "    axs.append(fig.add_subplot(gs[0, 4:]))\n",
    "    \n",
    "    try:\n",
    "        lk = dictobj(read_melt_lake_h5(fn))\n",
    "        \n",
    "        plot_IS2_imagery(fn=fn, imagery_filename=fn_imagery, **settings, axes=axs)\n",
    "        fig.tight_layout(pad=0.3, h_pad=0.3, w_pad=0.4)\n",
    "    except:\n",
    "        axs[0].text(0.5, 0.5, 'plotting error', fontsize=12, ha='center', va='center', transform=axs[0].transAxes)\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # plt.close(fig)\n",
    "    fig.savefig(fn_plot, dpi=600)\n",
    "\n",
    "    # display(Image(fn_plot))\n",
    "\n",
    "print('\\n\\nscp -i ~/.ssh/lumosKey parndt@132.239.169.168:%s /mnt/c/Users/phili/Documents/IceLakesMethods/gooddata/' % fn_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14bd493-0b36-4566-bf47-b6ce3f32f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poi = ee.Geometry.Point(lk.lon, lk.lat)\n",
    "# roi = poi.buffer(1000)\n",
    "# col = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED').filterBounds(roi).filterDate('2019-06-01', '2019-06-30')\n",
    "# info = col.getInfo()\n",
    "# info = col.getInfo()\n",
    "# for f in info['features']:\n",
    "#     print(f['properties']['system:time_start'])\n",
    "print('scp -i ~/.ssh/lumosKey parndt@132.239.169.168:%s /mnt/c/Users/phili/Documents/IceLakesMethods/gooddata/' % fn_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554243b-b293-4008-aa33-550d66096d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_format_out = '%Y-%m-%dT%H:%M:%SZ'\n",
    "lake_mean_time_string = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "base = '/Users/parndt/jupyterprojects/IceLakesRun2/methods_data/'\n",
    "fn = base + 'lake_09022414_GrIS_2019_simplified_GRE_2000_CW_ATL03_20190617064249_12220303_006_02_gt2l_0017.h5'\n",
    "lk = dictobj(read_melt_lake_h5(fn))\n",
    "\n",
    "image = ee.Image('LANDSAT/LC08/C02/T1/LC08_007012_20190617')\n",
    "image_timestamp = image.get('system:time_start').getInfo()\n",
    "image_datetime = datetime.fromtimestamp(image_timestamp/1000, tz=timezone.utc)\n",
    "image_time_string = datetime.strftime(image_datetime, time_format_out)\n",
    "image_center_time = image.get('SCENE_CENTER_TIME').getInfo()\n",
    "image_date_acquired = image.get('DATE_ACQUIRED').getInfo()\n",
    "\n",
    "time_format_out = '%Y-%m-%dT%H:%M:%SZ'\n",
    "lake_mean_delta_time = lk.mframe_data.dt.mean()\n",
    "ATLAS_SDP_epoch_datetime = datetime(2018, 1, 1, tzinfo=timezone.utc) # 2018-01-01:T00.00.00.000000 UTC, from ATL03 data dictionary \n",
    "ATLAS_SDP_epoch_timestamp = datetime.timestamp(ATLAS_SDP_epoch_datetime)\n",
    "lake_mean_timestamp = ATLAS_SDP_epoch_timestamp + lake_mean_delta_time\n",
    "lake_mean_datetime = datetime.fromtimestamp(lake_mean_timestamp, tz=timezone.utc)\n",
    "lake_mean_time_string = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "\n",
    "print('lake time calculated here:   ', lake_mean_time_string)\n",
    "print('lake time from saved file:   ', lk.date_time)\n",
    "print('')\n",
    "print('image center time:           ', image_center_time)\n",
    "print('image date acquired:         ', image_date_acquired)\n",
    "print('image time from earth engine:', image_time_string)\n",
    "\n",
    "timediff = image_datetime - lake_mean_datetime\n",
    "timediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604c0ae-2d66-408e-acc8-824899255477",
   "metadata": {},
   "outputs": [],
   "source": [
    "timediff = ee.Date(lake_mean_timestamp*1000).difference(image.get('system:time_start'), 'second').abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cde749-de46-43b6-8564-0aa601bb54af",
   "metadata": {},
   "outputs": [],
   "source": [
    "timediff.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8ce22-37b5-40c5-a1a5-65a728b40cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Date(lake_mean_timestamp*1000).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa0cfb-d868-4c50-8e1e-f449f82f26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.get('system:time_start').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c964d-020c-4d41-b226-ce001999ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(0, tzinfo=timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db3013e-0842-4ef1-972d-64d2ee1f0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605ebef-a691-4fcb-9b0e-7b253e24376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.timestamp(datetime(1970, 1, 1, 0, 0, tzinfo=timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae1ab5-0fc5-4b25-978d-f810e94236ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b377f-9e6b-4bf6-8b8f-842dc8ec3315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84bee7-df92-4359-9f73-b510da92df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "is2datetime = datetime.strptime('2020-05-11T13:04:24Z', '%Y-%m-%dT%H:%M:%SZ')\n",
    "s2datetime = datetime.strptime('2020-04-11T15:23:58Z', '%Y-%m-%dT%H:%M:%SZ')\n",
    "timediff = s2datetime - is2datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7e519-f273-4f23-ae42-e9e9e3bc8f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'%s' % (timediff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56fc6e7-1b0d-43ee-82c6-1ce6972ab06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL03_20190810040312_06580403_006_02_gt3l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a5a8a-eadd-4627-8a65-f8a7b074bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk.granule_id, lk.gtx, lk.beam_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf5e759-3359-4875-b895-fe349cc2a05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16609d2-17fd-4d36-addc-2b6c4188c4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641174c-c4f0-471f-b6b3-92d44cc2ff19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232bc2ee-8a6e-41d8-9487-62d4e39c0d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9314e5-5dbe-4c80-a96e-b4e84d847609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60baf3-70e8-42ad-8b43-3c575fd58ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118c210-4547-4086-ac07-64f188c136ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d338fb-a24c-49a3-9881-93f44530c055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0d138-5dd8-40e9-bc77-376de6c05fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.close('all')\n",
    "\n",
    "settings = {\n",
    "    're_download': True,\n",
    "    'img_aspect': 1.0,\n",
    "    'days_buffer': 5,\n",
    "    'gamma_value': 1.0\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=[10,4.35])\n",
    "gs = fig.add_gridspec(ncols=9, nrows=1)\n",
    "\n",
    "axs = []\n",
    "axs.append(fig.add_subplot(gs[0, :4])) \n",
    "axs.append(fig.add_subplot(gs[0, 4:]))\n",
    "\n",
    "toplot = amery\n",
    "# toplot = usulluup_sermia\n",
    "# toplot = ice_cover\n",
    "# toplot = shackleton\n",
    "# toplot = tucker\n",
    "# toplot = more_typical\n",
    "lk = dictobj(read_melt_lake_h5(toplot['fn']))\n",
    "plot_IS2_imagery(**toplot, **settings, axes=axs)\n",
    "fig.tight_layout(pad=0.3, h_pad=0.3, w_pad=0.4)\n",
    "\n",
    "fig.savefig('plots/example_xxx.jpg', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23fa78-4cf2-4cdd-b46c-474a65d93f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/detection_out_data/'\n",
    "base = '/Users/parndt/jupyterprojects/IceLakesRun2/detection_out_data/'\n",
    "\n",
    "amery = {\n",
    "    'name': 'Amery Ice Shelf',\n",
    "    'fn': base + 'lake_09661801_AIS_2021-22_simplified_ANT_1000_East_B-C_ATL03_20220118022134_04091412_006_01_gt3l_0006.h5',\n",
    "    'gamma_value': 0.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "shackleton = {\n",
    "    'name': 'Shackleton Ice Shelf',\n",
    "    'fn': base + 'lake_09996401_AIS_2019-20_simplified_ANT_1000_East_C-Cp_ATL03_20200224204246_09180610_006_01_gt2r_0002.h5',\n",
    "    'gamma_value': 0.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "tucker = {\n",
    "    'name': 'Tucker Glacier',\n",
    "    'fn': base + 'lake_09993680_AIS_2020-21_simplified_ANT_1000_East_Dp-E_ATL03_20210128124234_05421012_006_01_gt3r_0001.h5',\n",
    "    'gamma_value': 0.75,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "nansen = {\n",
    "    'name': 'Nansen Ice Shelf',\n",
    "    'fn': base + 'lake_09999825_AIS_2020-21_simplified_ANT_1000_East_Dp-E_ATL03_20210106141527_02071012_006_01_gt3l_0014.h5',\n",
    "    'gamma_value': 0.7,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "koettlitz = {\n",
    "    'name': 'Koettlitz Glacier',\n",
    "    'fn': base + 'lake_09999778_AIS_2021-22_simplified_ANT_1000_East_E-Ep_ATL03_20220108204642_02681412_006_01_gt2l_0005.h5',\n",
    "    'gamma_value': 0.8,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "byrd = {\n",
    "    'name': 'Byrd Glacier',\n",
    "    'fn': base + 'lake_09962662_AIS_2020-21_simplified_ANT_1000_East_E-Ep_ATL03_20210111010129_02751011_006_01_gt2l_0002.h5',\n",
    "    'gamma_value': 0.8,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "nimrod = {\n",
    "    'name': 'Nimrod Glacier',\n",
    "    'fn': base + 'lake_09998718_AIS_2021-22_simplified_ANT_1000_East_E-Ep_ATL03_20220127202459_05581411_006_01_gt3l_0000.h5',\n",
    "    'gamma_value': 0.8,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "scott_other = {\n",
    "    'name': 'Scott Glacier',\n",
    "    'fn': base + 'lake_09479207_AIS_2021-22_test_ross_ATL03_20220104191501_02061411_006_01_gt3l_0000.h5',\n",
    "    'imagery_filename': 'imagery/modis_scott_2022-01-04.tif',\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "scott = {\n",
    "    'name': 'Scott Glacier',\n",
    "    'fn': base + 'lake_09999381_AIS_2018-19_simplified_ANT_1000_West_Ep-F_ATL03_20190313202056_11510211_006_02_gt3l_0003.h5',\n",
    "    'imagery_filename': 'imagery/modis_mercer-scott_2019-01-02.tif',\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "mercer = {\n",
    "    'name': 'Mercer Ice Stream',\n",
    "    'fn': base + 'lake_09998311_AIS_2018-19_simplified_ANT_1000_West_Ep-F_ATL03_20190102075052_00740211_006_02_gt1l_0000.h5',\n",
    "    'imagery_filename': 'imagery/modis_mercer-scott_2019-01-02.tif',\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "pineisland = {\n",
    "    'name': 'Pine Island',\n",
    "    'fn': base + 'lake_09915690_AIS_2019-20_simplified_ANT_1000_West_G-H_ATL03_20191224015224_13460512_006_01_gt2l_0000.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "wilkins = {\n",
    "    'name': 'Wilkins Ice Shelf',\n",
    "    'fn': base + 'lake_09941497_AIS_2022-23_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20230206171923_07351812_006_01_gt2r_0002.h5',\n",
    "    'gamma_value': 0.75,\n",
    "    'xlm': [30, 900],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "bach = {\n",
    "    'name': 'Bach Ice Shelf',\n",
    "    'fn': base + 'lake_09650303_AIS_2019-20_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20200118094903_03460610_006_01_gt3r_0025.h5',\n",
    "    'gamma_value': 0.75,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "georgevi = {\n",
    "    'name': 'George VI Ice Shelf',\n",
    "    'fn': base + 'lake_09809632_AIS_2022-23_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20230129173611_06131812_006_01_gt3r_0080.h5',\n",
    "    'gamma_value': 0.65,\n",
    "    'xlm': [95, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "larsenc = {\n",
    "    'name': 'Larsen C Ice Shelf',\n",
    "    'fn': base + 'lake_09927824_AIS_2021-22_simplified_ANT_1000_Peninsula_I-Ipp_ATL03_20220208212635_07421410_006_01_gt2l_0000.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "filchner = {\n",
    "    'name': 'Filchner Ice Shelf',\n",
    "    'fn': base + 'lake_09999779_AIS_2018-19_simplified_ANT_1000_East_Jpp-K_ATL03_20190217224511_07860211_006_02_gt1l_0000.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'max_cloud_prob': 30,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "riiser_larsen = {\n",
    "    'name': 'Riiser-Larsen Ice Shelf',\n",
    "    'fn': base + 'lake_09964391_AIS_2019-20_simplified_ANT_1000_East_K-A_ATL03_20200128053234_04960610_006_01_gt2r_0001.h5',\n",
    "    'gamma_value': 0.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "riiser_larsen2 = {\n",
    "    'name': 'Riiser-Larsen Ice Shelf',\n",
    "    'fn': base + 'lake_09999986_AIS_2019-20_simplified_ANT_1000_East_K-A_ATL03_20200210044152_06940610_006_01_gt3r_0003.h5',\n",
    "    'gamma_value': 0.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "fimbul = {\n",
    "    'name': 'Fimbul Ice Shelf',\n",
    "    'fn': base + 'lake_09971131_AIS_2019-20_simplified_ANT_1000_East_A-Ap_ATL03_20200115044852_02970610_006_01_gt1r_0001.h5',\n",
    "    'gamma_value': 0.75,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "nivil = {\n",
    "    'name': 'Nivil Ice Shelf',\n",
    "    'fn': base + 'lake_07269598_AIS_2019-20_simplified_ANT_1000_East_A-Ap_ATL03_20200116042313_03120610_006_01_gt2r_0002.h5',\n",
    "    'gamma_value': 0.6,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "roi_baudouin = {\n",
    "    'name': 'Roi Baudouin Ice Shelf',\n",
    "    'fn': base + 'lake_09999544_AIS_2019-20_simplified_ANT_1000_East_A-Ap_ATL03_20200201150322_05630612_006_01_gt2l_0005.h5',\n",
    "    'gamma_value': 0.6,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "roi_baudouin2 = {\n",
    "    'name': 'Roi Baudouin Ice Shelf',\n",
    "    'fn': base + 'lake_09999966_AIS_2019-20_simplified_ANT_1000_East_A-Ap_ATL03_20200123025757_04180610_006_01_gt2r_0003.h5',\n",
    "    'gamma_value': 0.6,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "#######################################################\n",
    "# GREENLAND\n",
    "usulluup_sermia = { # SW, 1\n",
    "    'name': 'Usulluup Sermia',\n",
    "    'fn': base + 'lake_05857276_GrIS_2019_simplified_GRE_2000_SW_ATL03_20190818034635_07800403_006_02_gt1l_0000.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "jakobshavn_isbrae = { # CW, 2\n",
    "    'name': 'Jakobshavn Isbrae',\n",
    "    'fn': base + 'lake_07661472_GrIS_2019_simplified_GRE_2000_CW_ATL03_20190716051841_02770403_006_02_gt3l_0014.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "alison_gletscher = { # NW, 3\n",
    "    'name': 'Alison Gletscher',\n",
    "    'fn': base + 'lake_05549443_GrIS_2019_simplified_GRE_2000_NW_ATL03_20190805043712_05820403_006_02_gt1l_0003.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "humboldt_gletscher = { # NO, 4\n",
    "    'name': 'Humboldt Gletscher',\n",
    "    'fn': base + 'lake_08835579_GrIS_2021_simplified_GRE_2000_NO_ATL03_20210726182948_05061203_006_01_gt2r_0002.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "storstrommen = { # NE, 5\n",
    "    'name': 'Storstrommen',\n",
    "    'fn': base + 'lake_02254624_GrIS_2021_simplified_GRE_2000_NE_ATL03_20210720053125_04061205_006_01_gt3r_0042.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "kangerlussuaq = { # CE, 6\n",
    "    'name': 'Kangerlussuaq',\n",
    "    'fn': base + 'lake_09456922_GrIS_2022_simplified_GRE_2000_CE_ATL03_20220815111248_08331605_006_01_gt1r_0002.h5',\n",
    "    'gamma_value': 1.4,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "helheimgletscher = { # SE, 7\n",
    "    'name': 'Helheim Gletscher',\n",
    "    'fn': base + 'lake_09906186_GrIS_2021_simplified_GRE_2000_SE_ATL03_20210622185325_13741103_006_01_gt1r_0001.h5',\n",
    "    'gamma_value': 1.1,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "ryder_gletscher = { # NO, 8 (one of the deepest good-looking lakes)\n",
    "    'name': 'Ryder Gletscher',\n",
    "    'fn': base + 'lake_09803461_GrIS_2019_simplified_GRE_2000_NO_ATL03_20190902161841_10170404_006_02_gt1l_0000.h5',\n",
    "    'gamma_value': 1.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "nioghalvfjerdsfjorden = { # NO, 9 (one of the longest good-looking lakes)\n",
    "    'name': 'Nioghalvfjerdsfjorden',\n",
    "    'fn': base + 'lake_09130391_GrIS_2020_simplified_GRE_2000_NE_ATL03_20200802222701_05890805_006_01_gt2l_0004.h5',\n",
    "    'gamma_value': 1.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "sermeq_kangaasarsuup = { # SW, 10 \n",
    "    'name': 'Sermeq Kangaasarsuup',\n",
    "    'fn': base + 'lake_08989585_GrIS_2020_simplified_GRE_2000_SW_ATL03_20200721114126_03990803_006_01_gt1l_0002.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "harald_moltke_brae = { # NW, 11\n",
    "    'name': 'Harald Moltke Brae',\n",
    "    'fn': base + 'lake_09019555_GrIS_2019_simplified_GRE_2000_NW_ATL03_20190730053649_04910403_006_02_gt2l_0004.h5',\n",
    "    'gamma_value': 1.3,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "eielson_hare_fjord = { # CE, 12\n",
    "    'name': 'Eielson Gletscher',\n",
    "    'fn': base + 'lake_09916382_GrIS_2021_simplified_GRE_2000_CE_ATL03_20210728051446_05281205_006_01_gt2r_0002.h5',\n",
    "    'gamma_value': 1.3,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "academy = { # NO, 13\n",
    "    'name': 'Academy Glacier',\n",
    "    'fn': base + 'lake_09687033_GrIS_2022_simplified_GRE_2000_NO_ATL03_20220822111641_09401604_006_01_gt2r_0003.h5',\n",
    "    'gamma_value': 1.3,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "sermeq_silarleq = { # CW, 13\n",
    "    'name': 'Sermeq Silarleq',\n",
    "    'fn': base + 'lake_08819453_GrIS_2019_simplified_GRE_2000_CW_ATL03_20190818034635_07800403_006_02_gt1l_0001.h5',\n",
    "    'gamma_value': 1.3,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "highest_quality = {\n",
    "    'name': '\"Highest Quality\" ICESat-2 Lake',\n",
    "    'fn': base + 'lake_02254624_GrIS_2021_simplified_GRE_2000_NE_ATL03_20210720053125_04061205_006_01_gt3r_0042.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "deepest = {\n",
    "    'name': 'Deepest ICESat-2 Lake',\n",
    "    'fn': base + 'lake_09803461_GrIS_2019_simplified_GRE_2000_NO_ATL03_20190902161841_10170404_006_02_gt1l_0000.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "deepest2 = {\n",
    "    'name': 'Deepest ICESat-2 Lake',\n",
    "    'fn': base + 'lake_09974979_GrIS_2019_simplified_GRE_2000_NE_ATL03_20190803021956_05500403_006_02_gt2l_0004.h5',\n",
    "    'gamma_value': 1.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "longest = { \n",
    "    'name': 'Longest ICESat-2 Lake',\n",
    "    'fn': base + 'lake_09130391_GrIS_2020_simplified_GRE_2000_NE_ATL03_20200802222701_05890805_006_01_gt2l_0004.h5',\n",
    "    'gamma_value': 1.5,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "multiple_basins = {\n",
    "    'name': 'ICESat-2 Lake with Multiple Basins',\n",
    "    'fn': base + 'lake_09999207_AIS_2019-20_simplified_ANT_1000_East_B-C_ATL03_20200207122923_06530612_006_01_gt3r_0020.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "more_typical = {\n",
    "    'name': 'a more typical ICESat-2 lake...',\n",
    "    'fn': base + 'lake_09999996_GrIS_2019_simplified_GRE_2000_CW_ATL03_20190712052659_02160403_006_02_gt2l_0007.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "shelf_bench = {\n",
    "    'name': 'What is this weird lake?',\n",
    "    'fn': base + 'lake_09928802_AIS_2020-21_simplified_ANT_1000_East_C-Cp_ATL03_20201118081610_08420910_006_01_gt2l_0000.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, 880],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "ice_cover = {\n",
    "    'name': 'An ICESat-2 Lake With Ice Cover',\n",
    "    'fn': base + 'lake_09769063_GrIS_2019_simplified_GRE_2000_NW_ATL03_20190907030457_10850403_006_02_gt2r_0005.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "afterpulses = {\n",
    "    'name': 'Afterpulses Removed',\n",
    "    'fn': base + 'lake_09586908_GrIS_2022_simplified_GRE_2000_CW_ATL03_20220714010847_03381603_006_02_gt2r_0015.h5',\n",
    "    'gamma_value': 1.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "doline_dammed = {\n",
    "    'name': 'ICESat-2 Lake Dammed by Doline',\n",
    "    'fn': base + 'lake_09991923_AIS_2018-19_simplified_ANT_1000_East_B-C_ATL03_20190123173555_04010210_006_02_gt2l_0003.h5',\n",
    "    'gamma_value': 0.3,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "longest_ant = {\n",
    "    'name': 'Longest ICESat-2 Lake',\n",
    "    'fn': base + 'lake_09992056_AIS_2018-19_simplified_ANT_1000_East_B-C_ATL03_20190123173555_04010210_006_02_gt2r_0008.h5',\n",
    "    'gamma_value': 0.3,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "furthest_south = {\n",
    "    'name': 'Furthest South',\n",
    "    'fn': base + 'lake_09998311_AIS_2018-19_simplified_ANT_1000_West_Ep-F_ATL03_20190102075052_00740211_006_02_gt1l_0000.h5',\n",
    "    'imagery_filename': 'imagery/modis_mercer-scott_2019-01-02.tif',\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}\n",
    "\n",
    "rift_foot = {\n",
    "    'name': 'Rift with bottom return?',\n",
    "    'fn': base + 'lake_09994291_AIS_2020-21_simplified_ANT_1000_West_F-G_ATL03_20201125223347_09580910_006_01_gt2l_0000.h5',\n",
    "    'gamma_value': 2.0,\n",
    "    'xlm': [None, None],\n",
    "    'ylm': [None, None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069f612-f164-4124-a3e4-55ec12dca2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "\n",
    "settings = {\n",
    "    're_download': True,\n",
    "    'img_aspect': 1.0,\n",
    "    'days_buffer': 5,\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=[10,4.5])\n",
    "gs = fig.add_gridspec(ncols=3, nrows=1)\n",
    "\n",
    "axs = []\n",
    "axs.append(fig.add_subplot(gs[0, 0])) \n",
    "axs.append(fig.add_subplot(gs[0, 1:]))\n",
    "\n",
    "toplot = amery\n",
    "# toplot = usulluup_sermia\n",
    "# toplot = ice_cover\n",
    "# toplot = shackleton\n",
    "# toplot = tucker\n",
    "# toplot = more_typical\n",
    "lk = dictobj(read_melt_lake_h5(toplot['fn']))\n",
    "plot_IS2_imagery(**toplot, **settings, axes=axs)\n",
    "fig.tight_layout(pad=0.3, h_pad=0.3, w_pad=0.4)\n",
    "\n",
    "fig.savefig('plots/example_xxx.jpg', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d3553-0b7c-4709-a0b7-ded6dd86f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lk.lat, lk.lon, lk.date_time, lk.rgt, lk.gtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b479d-a23f-4408-8908-c6dde57c7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelst = [\n",
    "'/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/detection_out_data/lake_09999733_AIS_2019-20_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20200204213749_06130612_006_01_gt3l_0053.h5',\n",
    "'/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/detection_out_data/lake_09999905_AIS_2022-23_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20230129173611_06131812_006_01_gt1l_0002.h5',\n",
    "'/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/detection_out_data/lake_09955969_AIS_2020-21_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20210213150425_07881010_006_01_gt1r_0001.h5',\n",
    "'/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/detection_out_data/lake_09998273_AIS_2019-20_simplified_ANT_1000_Peninsula_Hp-I_ATL03_20200106230147_01710612_006_01_gt3l_0006.h5',\n",
    "'/Volumes/nox/Philipp/IceLakesRun2/GlacierLakeDetectionICESat2/detection_out_data/lake_09999182_AIS_2022-23_simplified_ANT_1000_Peninsula_I-Ipp_ATL03_20230220160301_09481812_006_01_gt2l_0000.h5',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb2454-db20-4a2a-8512-9ebe910ee54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in filelst:\n",
    "    settings = {\n",
    "        're_download': False,\n",
    "        'img_aspect': 1.4,\n",
    "        'days_buffer': 30,\n",
    "        'xlm': [None, None],\n",
    "        'ylm': [None, None],\n",
    "        'gamma_value': 1.0,\n",
    "    }\n",
    "    plot_IS2_imagery(fn=fn, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657d5ad-2c5e-45b4-9195-47853839bd31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65f2b41-c194-44fa-bc15-39706e3a2c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544822b5-9c9b-4d08-aeaa-3c2f938234ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4c3d3-4422-4c11-9608-2e208c6010b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0af2c1-2fcf-4992-b253-57b0a31c76c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3806f-cad1-4063-830c-852ed105d28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cf50a-b6e4-41ea-b366-9f41cba3d228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040b626-832d-426d-aeb7-c29f8543b4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7db605a-658d-4fd7-9959-b7d56ba8a46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7a811-733c-4e5c-b554-9a4bab59244e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b01777-4a80-4386-a8b5-579637ebf992",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[32,16], dpi=30)\n",
    "gs = fig.add_gridspec(6, 18)\n",
    "axs = []\n",
    "axs.append(fig.add_subplot(gs[1:5, 3:6])) # greenland\n",
    "axs.append(fig.add_subplot(gs[1:5, 9:15])) # antarctica\n",
    "for j in range(0, 18, 3):\n",
    "    axs.append(fig.add_subplot(gs[0, j]))\n",
    "    axs.append(fig.add_subplot(gs[0, j+1:j+3]))\n",
    "for i in range(1,5):\n",
    "    for j in np.array([0, 2, 5])*3:\n",
    "        axs.append(fig.add_subplot(gs[i, j]))\n",
    "        axs.append(fig.add_subplot(gs[i, j+1:j+3]))\n",
    "for j in range(0, 18, 3):\n",
    "    axs.append(fig.add_subplot(gs[5, j]))\n",
    "    axs.append(fig.add_subplot(gs[5, j+1:j+3]))\n",
    "\n",
    "ax = axs[0]\n",
    "gre_bound.plot(color='k', ax=ax, lw=0.5)\n",
    "gre_gdf_merged.exterior.plot(color='gray', ax=ax, lw=0.3)\n",
    "ax.axis('off')\n",
    "\n",
    "ax = axs[1]\n",
    "ant_gdf_merged.exterior.plot(color='gray', ax=ax, lw=0.3)\n",
    "ant_gdf_shelf.plot(color='blue', alpha=0.1, ax=ax, lw=0)\n",
    "ant_bound.plot(color='k', ax=ax, lw=0.5)\n",
    "ant_gdf_shelf.boundary.plot(color='k', ax=ax, lw=0.5)\n",
    "ax.axis('off')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_ticks([])\n",
    "    ax.yaxis.set_ticks([])\n",
    "\n",
    "fig.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.text(0.5, 0.5, '%i'%i, ha='center', va='center', transform=ax.transAxes, fontsize=20)\n",
    "\n",
    "fig.tight_layout(pad=1, h_pad=1, w_pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5a6ea-8068-4dfd-8a9c-3bce02acddc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb2e3c-0bb7-4dfa-b10b-33e6a01d1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/Users/parndt/jupyterprojects/IceLakesRun2/detection_out_data/'\n",
    "fn = 'lake_09022414_GrIS_2019_simplified_GRE_2000_CW_ATL03_20190617064249_12220303_006_02_gt2l_0017.h5'\n",
    "lk = dictobj(read_melt_lake_h5(base+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7b9cf-2579-4eb7-9d4c-106910d04586",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_mean_delta_time = lk.mframe_data.dt.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a644d5c-9ff7-48c7-a92b-a6201956fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_mean_delta_time = lk.mframe_data.dt.mean()\n",
    "ATLAS_SDP_epoch = '2018-01-01:T00.00.00.000000Z'  # UTC, from ATL03 data dictiornary \n",
    "ATLAS_SDP_epoch_format = '%Y-%m-%d:T%H.%M.%S.%fZ'  # UTC, from ATL03 data dictiornary\n",
    "time_format_out = '%Y-%m-%d %H:%M:%S'\n",
    "ATLAS_SDP_epoch_datetime = datetime.strptime(ATLAS_SDP_epoch, ATLAS_SDP_epoch_format)\n",
    "ATLAS_SDP_epoch_timestamp = datetime.timestamp(ATLAS_SDP_epoch_datetime)\n",
    "lake_mean_timestamp = ATLAS_SDP_epoch_timestamp + lake_mean_delta_time\n",
    "lake_mean_datetime = datetime.fromtimestamp(lake_mean_timestamp)\n",
    "lake_mean_time_string = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "lake_mean_time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c76e8a-6302-44db-91c9-cfcae17257db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagery_prod_id = 'LC08_L1TP_007012_20190617_20200827_02_T1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1bd48-81bf-46bb-a5a8-b42353fad5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk.lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b11e01-e79a-47ba-8963-6244d19e4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "lk.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7621a-7a74-4470-b8b6-b6e5139a0032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeicelakes-env",
   "language": "python",
   "name": "eeicelakes-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
